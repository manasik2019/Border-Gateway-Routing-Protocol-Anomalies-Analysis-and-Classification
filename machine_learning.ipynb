{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b54b8789",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bc5465",
   "metadata": {},
   "source": [
    "# MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff494166",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP Classifier\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "WannaCrypt=pd.read_csv('WannaCrypt.csv')\n",
    "Nimda=pd.read_csv('Nimda.csv')\n",
    "Slammer=pd.read_csv('Slammer.csv')\n",
    "Moscow_blackout = pd.read_csv('Moscow_blackout.csv')\n",
    "Code_Red_I = pd.read_csv('Code_Red_I.csv')\n",
    "\n",
    "Datasets = [WannaCrypt, Nimda,Slammer, Moscow_blackout,Code_Red_I ]\n",
    "names = ['WannaCrypt', 'Nimda','Slammer', 'Moscow_blackout','Code_Red_I' ]\n",
    "\n",
    "for i in range(len(Datasets)):\n",
    "\n",
    "    X = Datasets[i].drop(['H+M','H','M','S','MED1','MED2','MED3','MED4','MED5','MED6','MED7','MED8','MED9',\n",
    "                          'MED10','MED11','MAL1','MAL2','MAL3','MAL4','MAL5','MAL6','MAL7','MAL8','MAL9',\n",
    "                          'Classification'],axis=1)\n",
    "    y = Datasets[i]['Classification']\n",
    "\n",
    "    #Train, test and split the dataset. Random number generator, with popular integer see numbers are 0 and 42\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "    #Pre-processing - transformation, etc...\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit only to the training data\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    # Now apply the transformations to the data:\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    parameter_space = {\n",
    "    'activation' : ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'solver' : ['lbfgs', 'sgd', 'adam'] }\n",
    "\n",
    "    #Create an MLP model\n",
    "    clf = GridSearchCV(MLPClassifier(max_iter=2000), parameter_space, n_jobs=-1, cv=3)\n",
    "\n",
    "    #Fit the model\n",
    "    classifier = clf.fit(X_train,y_train)\n",
    "    #Prediction \n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print('Best parameters found for', names[i],'Dataset :\\n', clf.best_params_)\n",
    "   \n",
    "    #Model Evaluation\n",
    "    print(\"Confusion Matrix is \")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\n\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Plot non-normalized confusion matrix\n",
    "    titles_options = [(\"Confusion matrix, without normalization for \"+ names[i] + \" Dataset\", None),\n",
    "                  (\"Normalized confusion matrix for \"+ names[i] + \" Dataset\", 'true')]\n",
    "    for title, normalize in titles_options:\n",
    "        disp = plot_confusion_matrix(classifier, X_test, y_test,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=normalize)\n",
    "        disp.ax_.set_title(title)\n",
    "\n",
    "        print(title)\n",
    "        print(disp.confusion_matrix)\n",
    "\n",
    "    plt.show()\n",
    "    print(':\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d93e6b1",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e130fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Classifier\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Load dataset and explore dataset\n",
    "WannaCrypt=pd.read_csv('WannaCrypt.csv')\n",
    "Nimda=pd.read_csv('Nimda.csv')\n",
    "Slammer=pd.read_csv('Slammer.csv')\n",
    "Moscow_blackout = pd.read_csv('Moscow_blackout.csv')\n",
    "Code_Red_I = pd.read_csv('Code_Red_I.csv')\n",
    "\n",
    "Datasets = [WannaCrypt, Nimda,Slammer, Moscow_blackout,Code_Red_I ]\n",
    "names = ['WannaCrypt', 'Nimda','Slammer', 'Moscow_blackout','Code_Red_I' ]\n",
    "\n",
    "for i in range(len(Datasets)):\n",
    "\n",
    "    #Feature selection: split the dataset into features (independent variables) and target (dependent variable)\n",
    "    X = Datasets[i].drop(['H+M','H','M','S','MED1','MED2','MED3','MED4','MED5','MED6','MED7',\n",
    "                          'MED8','MED9','MED10','MED11','MAL1','MAL2','MAL3','MAL4','MAL5','MAL6',\n",
    "                          'MAL7','MAL8','MAL9','Classification'],axis=1)\n",
    "    y = Datasets[i]['Classification']\n",
    "\n",
    "    # Split dataset into training set and test set,70% training and 30% test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "    parameter_space = {\n",
    "        'criterion': ['gini', 'entropy'] }\n",
    "\n",
    "    # Create Decision Tree classifer object\n",
    "    clf = GridSearchCV(DecisionTreeClassifier(random_state=1234), parameter_space, n_jobs=-1, cv=3)\n",
    "\n",
    "    # Train Decision Tree Classifer\n",
    "    clf = clf.fit(X_train,y_train)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print('Best parameters found for', names[i],'Dataset :\\n', clf.best_params_)\n",
    "\n",
    "    # Model Accuracy\n",
    "    print(\"\\n\")\n",
    "    print(\"Accuracy for 70% training set and 30% test set :\",\n",
    "              metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "    #Confusion matrix\n",
    "    print(\"Confusion Matrix is\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\n\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\n\")\n",
    "\n",
    "        # Plot non-normalized confusion matrix\n",
    "    titles_options = [(\"Confusion matrix, without normalization for \"+ names[i] + \" Dataset\", None),\n",
    "                      (\"Normalized confusion matrix for \"+ names[i] + \" Dataset\", 'true')]\n",
    "    for title, normalize in titles_options:\n",
    "        disp = plot_confusion_matrix(clf, X_test, y_test,\n",
    "                                     #display_labels=class_names,\n",
    "                                     cmap=plt.cm.Blues,\n",
    "                                     normalize=normalize)\n",
    "        disp.ax_.set_title(title)\n",
    "\n",
    "        print(title)\n",
    "        print(disp.confusion_matrix)\n",
    "\n",
    "    plt.show()\n",
    "    print(':\\n')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29847181",
   "metadata": {},
   "source": [
    "# KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdf5803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN classifier \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    " \n",
    "%matplotlib inline\n",
    " \n",
    "#Import the data set\n",
    "WannaCrypt=pd.read_csv('WannaCrypt.csv')\n",
    "Nimda=pd.read_csv('Nimda.csv')\n",
    "Slammer=pd.read_csv('Slammer.csv')\n",
    "Moscow_blackout = pd.read_csv('Moscow_blackout.csv')\n",
    "Code_Red_I = pd.read_csv('Code_Red_I.csv')\n",
    "\n",
    "for i in range(len(Datasets)):\n",
    "    Datasets = [WannaCrypt, Nimda,Slammer, Moscow_blackout,Code_Red_I ]\n",
    "    names = ['WannaCrypt', 'Nimda','Slammer', 'Moscow_blackout','Code_Red_I' ]\n",
    "    \n",
    "    dataset = Datasets[i].drop(['H+M','H','M','S','MED1','MED2','MED3','MED4','MED5','MED6','MED7',\n",
    "                              'MED8','MED9','MED10','MED11','MAL1','MAL2','MAL3','MAL4','MAL5','MAL6',\n",
    "                              'MAL7','MAL8','MAL9','Classification'],axis=1)\n",
    "    #Standardize the data set\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(dataset)\n",
    "    scaled_features = scaler.transform(dataset)\n",
    "    scaled_data = pd.DataFrame(scaled_features, columns = dataset.columns)\n",
    "\n",
    "    parameter_space = {\n",
    "        'n_neighbors': list(range(1,100)),\n",
    "        'weights': ['uniform', 'distance'] }\n",
    "\n",
    "    #Split the data set into training data and test data\n",
    "    X= scaled_data\n",
    "    y = Datasets[i]['Classification']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "    #Train the model and make predictions\n",
    "    model = GridSearchCV(KNeighborsClassifier(), parameter_space, n_jobs=-1, cv=3)\n",
    "    #model = KNeighborsClassifier(n_neighbors = 1)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print('Best parameters found for ',names[i],' Dataset :\\n', model.best_params_)\n",
    "\n",
    "    #Performance measurement\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    titles_options = [(\"Confusion matrix, without normalization for \"+ names[i] + \" Dataset\", None),\n",
    "                          (\"Normalized confusion matrix for \"+ names[i] + \" Dataset\", 'true')]\n",
    "    for title, normalize in titles_options:\n",
    "        disp = plot_confusion_matrix(model, X_test, y_test,\n",
    "                                         #display_labels=class_names,\n",
    "                                         cmap=plt.cm.Blues,\n",
    "                                         normalize=normalize)\n",
    "        disp.ax_.set_title(title)\n",
    "\n",
    "        print(title)\n",
    "        print(disp.confusion_matrix)\n",
    "\n",
    "    plt.show()\n",
    "    print(':\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ef837d",
   "metadata": {},
   "source": [
    "# Suppor Vector Machines Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56656788",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppor Vector MAchines Classifier\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    " \n",
    "\n",
    "#Import the dataset\n",
    "WannaCrypt=pd.read_csv('WannaCrypt.csv')\n",
    "Nimda=pd.read_csv('Nimda.csv')\n",
    "Slammer=pd.read_csv('Slammer.csv')\n",
    "Moscow_blackout = pd.read_csv('Moscow_blackout.csv')\n",
    "Code_Red_I = pd.read_csv('Code_Red_I.csv')\n",
    "\n",
    "for i in range(len(Datasets)):\n",
    "    Datasets = [WannaCrypt, Nimda,Slammer, Moscow_blackout,Code_Red_I ]\n",
    "    names = ['WannaCrypt', 'Nimda','Slammer', 'Moscow_blackout','Code_Red_I' ]\n",
    "    \n",
    "    dataset = Datasets[i].drop(['H+M','H','M','S','MED1','MED2','MED3','MED4','MED5','MED6','MED7',\n",
    "                              'MED8','MED9','MED10','MED11','MAL1','MAL2','MAL3','MAL4','MAL5','MAL6',\n",
    "                              'MAL7','MAL8','MAL9','Classification'],axis=1)\n",
    "    #Standardize the data set\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(dataset)\n",
    "    scaled_features = scaler.transform(dataset)\n",
    "    scaled_data = pd.DataFrame(scaled_features, columns = dataset.columns)\n",
    "\n",
    "    parameter_space = {\n",
    "        'kernel': ['linear', 'poly', 'rbf', 'sigmoid'] }\n",
    "\n",
    "    #Split the data set into training data and test data\n",
    "    X= scaled_data\n",
    "    y = Datasets[i]['Classification']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "    #Train the model and make predictions\n",
    "    model = GridSearchCV(SVC(), parameter_space, n_jobs=-1, cv=3)\n",
    "    #model = KNeighborsClassifier(n_neighbors = 1)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    \n",
    "    print('Best parameters found for ',names[i],' Dataset :\\n', model.best_params_)\n",
    "\n",
    "    #Performance measurement\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    titles_options = [(\"Confusion matrix, without normalization for \"+ names[i] + \" Dataset\", None),\n",
    "                          (\"Normalized confusion matrix for \"+ names[i] + \" Dataset\", 'true')]\n",
    "    for title, normalize in titles_options:\n",
    "        disp = plot_confusion_matrix(model, X_test, y_test,\n",
    "                                         cmap=plt.cm.Blues,\n",
    "                                         normalize=normalize)\n",
    "        disp.ax_.set_title(title)\n",
    "\n",
    "        print(title)\n",
    "        print(disp.confusion_matrix)\n",
    "\n",
    "    plt.show()\n",
    "    print(':\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a41ad29",
   "metadata": {},
   "source": [
    "# Random Forests Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41b883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forests Classifier\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    " \n",
    "#Import the dataset\n",
    "WannaCrypt=pd.read_csv('WannaCrypt.csv')\n",
    "Nimda=pd.read_csv('Nimda.csv')\n",
    "Slammer=pd.read_csv('Slammer.csv')\n",
    "Moscow_blackout = pd.read_csv('Moscow_blackout.csv')\n",
    "Code_Red_I = pd.read_csv('Code_Red_I.csv')\n",
    "\n",
    "for i in range(len(Datasets)):\n",
    "    Datasets = [WannaCrypt, Nimda,Slammer, Moscow_blackout,Code_Red_I ]\n",
    "    names = ['WannaCrypt', 'Nimda','Slammer', 'Moscow_blackout','Code_Red_I' ]\n",
    "    \n",
    "    dataset = Datasets[i].drop(['H+M','H','M','S','MED1','MED2','MED3','MED4','MED5','MED6','MED7',\n",
    "                              'MED8','MED9','MED10','MED11','MAL1','MAL2','MAL3','MAL4','MAL5','MAL6',\n",
    "                              'MAL7','MAL8','MAL9','Classification'],axis=1)\n",
    "\n",
    "    parameter_space = {\n",
    "        'n_estimators': list(range(50,151)),\n",
    "        'criterion': ['gini', 'entropy'] }\n",
    "                             \n",
    "    #Split the data set into training data and test data\n",
    "    X= dataset\n",
    "    y = Datasets[i]['Classification']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "\n",
    "    #Train the model and make predictions\n",
    "    model = GridSearchCV(RandomForestClassifier(), parameter_space, n_jobs=-1, cv=3)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print('Best parameters found for ',names[i],' Dataset :\\n', model.best_params_)\n",
    "\n",
    "    #Performance measurement\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    titles_options = [(\"Confusion matrix, without normalization for \"+ names[i] + \" Dataset\", None),\n",
    "                          (\"Normalized confusion matrix for \"+ names[i] + \" Dataset\", 'true')]\n",
    "    for title, normalize in titles_options:\n",
    "        disp = plot_confusion_matrix(model, X_test, y_test,\n",
    "                                         cmap=plt.cm.Blues,\n",
    "                                         normalize=normalize)\n",
    "        disp.ax_.set_title(title)\n",
    "\n",
    "        print(title)\n",
    "        print(disp.confusion_matrix)\n",
    "\n",
    "    plt.show()\n",
    "    print(':\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50bee41",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07dd454",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes Classifier\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    " \n",
    "\n",
    "#Import the dataset\n",
    "WannaCrypt=pd.read_csv('WannaCrypt.csv')\n",
    "Nimda=pd.read_csv('Nimda.csv')\n",
    "Slammer=pd.read_csv('Slammer.csv')\n",
    "Moscow_blackout = pd.read_csv('Moscow_blackout.csv')\n",
    "Code_Red_I = pd.read_csv('Code_Red_I.csv')\n",
    "c_SVC = np.logspace(start = 0, stop = 10, num = 100, base = 2 , dtype = 'float64')\n",
    "Datasets = [WannaCrypt, Nimda,Slammer, Moscow_blackout,Code_Red_I ]\n",
    "names = ['WannaCrypt', 'Nimda','Slammer', 'Moscow_blackout','Code_Red_I' ]\n",
    "\n",
    "for i in range(len(Datasets)):\n",
    "\n",
    "    \n",
    "    dataset = Datasets[i].drop(['H+M','H','M','S','MED1','MED2','MED3','MED4','MED5','MED6','MED7',\n",
    "                              'MED8','MED9','MED10','MED11','MAL1','MAL2','MAL3','MAL4','MAL5','MAL6',\n",
    "                              'MAL7','MAL8','MAL9','Classification'],axis=1)\n",
    "\n",
    "    #Split the data set into training data and test data\n",
    "    X= dataset\n",
    "    y = Datasets[i]['Classification']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "\n",
    "    #Train the model and make predictions\n",
    "    model = MultinomialNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "    #Performance measurement\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    titles_options = [(\"Confusion matrix, without normalization for \"+ names[i] + \" Dataset\", None),\n",
    "                          (\"Normalized confusion matrix for \"+ names[i] + \" Dataset\", 'true')]\n",
    "    for title, normalize in titles_options:\n",
    "        disp = plot_confusion_matrix(model, X_test, y_test,\n",
    "                                         #display_labels=class_names,\n",
    "                                         cmap=plt.cm.Blues,\n",
    "                                         normalize=normalize)\n",
    "        disp.ax_.set_title(title)\n",
    "\n",
    "        print(title)\n",
    "        print(disp.confusion_matrix)\n",
    "\n",
    "    plt.show()\n",
    "    print(':\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
